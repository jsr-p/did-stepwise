

## did-stepwise: python implementation of the stepwise DID estimator

The `did_sw` package is a Python implementation of the stepwise DID
estimator of
[Harmon](https://web.econ.ku.dk/nharmon/docs/harmon2022difference.pdf).

See:

- [Installation](#installation)
- [Example](#example)
- [Some theory](#some-theory)
- Docs (to be added)

## Installation

``` python
uv pip install git+https://github.com/jsr-p/did-stepwise
```

## Example

The following example takes outset in the data simulated from
[this](scripts/stata/harmon_sim_data.do) script taken from
[Harmonâ€™s](https://github.com/nikoharm/did_stepwise/blob/main/stepwise_examples.do)
repository.

``` python
import did_imp
import polars as pl
import seaborn as sns
import matplotlib.pyplot as plt
import plotnine as pn
```

``` python
import did_sw
from did_sw._testing import load_harmon_sim_data


data = load_harmon_sim_data()
transformed = data.transformed
df = data.raw

print(df.head())
```

    shape: (5, 12)
    â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ id  â”† t   â”† E   â”† K   â”† â€¦ â”† Y         â”† X1  â”† X2  â”† clust â”‚
    â”‚ --- â”† --- â”† --- â”† --- â”†   â”† ---       â”† --- â”† --- â”† ---   â”‚
    â”‚ i64 â”† i64 â”† i64 â”† i64 â”†   â”† f64       â”† f64 â”† i64 â”† i64   â”‚
    â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡
    â”‚ 1   â”† 1   â”† 2   â”† -1  â”† â€¦ â”† 1.0       â”† 0.0 â”† 50  â”† 10    â”‚
    â”‚ 1   â”† 2   â”† 2   â”† 0   â”† â€¦ â”† 2.8374085 â”† 0.0 â”† 50  â”† 10    â”‚
    â”‚ 1   â”† 3   â”† 2   â”† 1   â”† â€¦ â”† 6.2903514 â”† 0.0 â”† 50  â”† 10    â”‚
    â”‚ 1   â”† 4   â”† 2   â”† 2   â”† â€¦ â”† 11.157219 â”† 0.0 â”† 50  â”† 10    â”‚
    â”‚ 1   â”† 5   â”† 2   â”† 3   â”† â€¦ â”† 16.167133 â”† 0.0 â”† 50  â”† 10    â”‚
    â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

``` python
gp = df.group_by("E", "t").agg(pl.col("Y").mean())

fig, ax = plt.subplots(figsize=(10, 6))
ax = sns.lineplot(
    data=gp.to_pandas(),
    x="t",
    y="Y",
    hue="E",
    ax=ax,
)
for E in sorted(df["E"].unique()):
    ax.axvline(E, color="grey", linestyle="--")
ax.set(ylabel="Outcome", xlabel="$t$")
ax.legend(
    title="Treatment Cohort",
    loc="upper center",
    bbox_to_anchor=(0.5, -0.1),
    ncol=3,
    frameon=False,
)
sns.despine()
_ = fig.savefig(
    did_sw.utils.proj_folder() / "figs/example_avg.png", dpi=300, bbox_inches="tight"
)
plt.close(fig)  # quarto
```

![image](figs/example_avg.png)

``` python
result = did_sw.estimate(
    df,
    outcome="Y",
    group="E",
    time="t",
    unit="id",
    fes="t",
    horizons="event",
)
print(result.estimates)
```

    shape: (5, 7)
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ term â”† estimate â”† se       â”† tstat     â”† pval â”† lower    â”† upper    â”‚
    â”‚ ---  â”† ---      â”† ---      â”† ---       â”† ---  â”† ---      â”† ---      â”‚
    â”‚ str  â”† f64      â”† f64      â”† f64       â”† f64  â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ 0    â”† 0.501008 â”† 0.053665 â”† 9.335862  â”† 0.0  â”† 0.395825 â”† 0.606191 â”‚
    â”‚ 1    â”† 0.938361 â”† 0.090709 â”† 10.344759 â”† 0.0  â”† 0.760572 â”† 1.11615  â”‚
    â”‚ 2    â”† 1.44967  â”† 0.128739 â”† 11.260515 â”† 0.0  â”† 1.197341 â”† 1.701999 â”‚
    â”‚ 3    â”† 1.897607 â”† 0.183167 â”† 10.359964 â”† 0.0  â”† 1.538599 â”† 2.256615 â”‚
    â”‚ 4    â”† 2.756371 â”† 0.265588 â”† 10.378378 â”† 0.0  â”† 2.235819 â”† 3.276923 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Underneath the hood, the `did_sw` estimator uses the imputation
estimator of [BJS
estimator](https://academic.oup.com/restud/article/91/6/3253/7601390)
implemented in the `did_imp`
[package](https://github.com/jsr-p/did-imputation) on a transformed
dataset. Letâ€™s compute event study estimates using the imputation
estimator directly on the non-transformed data.

``` python
# Compare with imputation estimator
result_imp = did_imp.estimate(
    df,
    outcome="Y",
    group="E",
    time="t",
    unit="id",
    # NOTE: observe how the fixed effects here are `id + t` compared to `t` in
    # the `did_sw` estimator; also, the outcome above is the non-differenced
    # `Y`
    fes="id + t",
    horizons="event",
)
print(result_imp.estimates)
```

    shape: (5, 7)
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ term â”† estimate â”† se       â”† tstat     â”† pval       â”† lower    â”† upper    â”‚
    â”‚ ---  â”† ---      â”† ---      â”† ---       â”† ---        â”† ---      â”† ---      â”‚
    â”‚ str  â”† f64      â”† f64      â”† f64       â”† f64        â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ 0    â”† 0.512822 â”† 0.066833 â”† 7.673209  â”† 1.6875e-14 â”† 0.38183  â”† 0.643814 â”‚
    â”‚ 1    â”† 0.961453 â”† 0.104562 â”† 9.195015  â”† 0.0        â”† 0.75651  â”† 1.166395 â”‚
    â”‚ 2    â”† 1.472419 â”† 0.141071 â”† 10.437444 â”† 0.0        â”† 1.19592  â”† 1.748918 â”‚
    â”‚ 3    â”† 1.967783 â”† 0.193971 â”† 10.144728 â”† 0.0        â”† 1.587599 â”† 2.347966 â”‚
    â”‚ 4    â”† 2.749741 â”† 0.277446 â”† 9.910896  â”† 0.0        â”† 2.205946 â”† 3.293535 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Plotting the estimates

``` python
def plot_eventstudy(
    res: pl.DataFrame,
    breaks: list[int],
):
    """Helper to plot event study estimates"""
    p = (
        pn.ggplot(res, pn.aes(x="rel_year", y="estimate", color="group"))
        + pn.geom_point(position=pn.position_dodge(width=(w := 0.3)))
        + pn.geom_errorbar(
            pn.aes(ymin="lower", ymax="upper"),
            width=0.1,
            position=pn.position_dodge(width=w),
        )
        + pn.theme_classic()
        + pn.labs(
            x="Relative Time",
            y="Estimate",
            color="",
        )
        + pn.scale_x_continuous(breaks=breaks)
        + pn.geom_hline(yintercept=0, color="black", size=0.5, linetype="dotted")
        + pn.geom_vline(xintercept=0, color="black", size=0.5, linetype="dotted")
        + pn.theme(
            legend_position="bottom",
            axis_title=pn.element_text(size=14),
            axis_text=pn.element_text(size=12),
            legend_text=pn.element_text(size=12),
            legend_title=pn.element_text(size=13),
        )
    )
    return p


estimates = result.estimates.filter(pl.col("term").ne("average")).select(
    pl.col("term").cast(pl.Int8).alias("rel_year"),
    "estimate",
    "se",
    "lower",
    "upper",
    pl.lit("SWDD").alias("group"),
)
estimates_imp = result_imp.estimates.select(
    pl.col("term").cast(pl.Int8).alias("rel_year"),
    "estimate",
    "se",
    "lower",
    "upper",
    pl.lit("DID Imputation").alias("group"),
)
results = pl.concat([estimates, estimates_imp], how="vertical_relaxed").with_columns(
    pl.col("rel_year").cast(pl.Int8)
)

# Plot the estimates
p = plot_eventstudy(results, breaks=list(range(5)))
p.save(
    did_sw.utils.proj_folder() / "figs/example_estimates.png",
    width=10,
    height=6,
    transparent=False,
    verbose=False,
    dpi=300,
)
```

![image](figs/example_estimates.png)

### With covariates and clustered standard errors

``` python
# Clustered

r = did_sw.estimate(
    df,
    outcome="Y",
    group="E",
    time="t",
    unit="id",
    cluster_var="clust",
    fes="t",
    horizons="event",
)
print(r.estimates)

# Categorical
r = did_sw.estimate(
    df,
    outcome="Y",
    group="E",
    time="t",
    cluster_var="id",
    unit="id",
    covariates=["C(X2) : C(t)"],
    fes="t",
    horizons="event",
)
print(r.estimates)


# Continuous
r = did_sw.estimate(
    df,
    outcome="Y",
    group="E",
    time="t",
    cluster_var="id",
    unit="id",
    covariates=["-1 + X1 : C(t)"],
    fes="t",
    horizons="event",
)
print(r.estimates)
```

    shape: (5, 7)
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ term â”† estimate â”† se       â”† tstat     â”† pval â”† lower    â”† upper    â”‚
    â”‚ ---  â”† ---      â”† ---      â”† ---       â”† ---  â”† ---      â”† ---      â”‚
    â”‚ str  â”† f64      â”† f64      â”† f64       â”† f64  â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ 0    â”† 0.501008 â”† 0.059125 â”† 8.473706  â”† 0.0  â”† 0.385123 â”† 0.616893 â”‚
    â”‚ 1    â”† 0.938361 â”† 0.080797 â”† 11.613822 â”† 0.0  â”† 0.779999 â”† 1.096723 â”‚
    â”‚ 2    â”† 1.44967  â”† 0.11477  â”† 12.631044 â”† 0.0  â”† 1.22472  â”† 1.67462  â”‚
    â”‚ 3    â”† 1.897607 â”† 0.158204 â”† 11.994648 â”† 0.0  â”† 1.587526 â”† 2.207688 â”‚
    â”‚ 4    â”† 2.756371 â”† 0.258764 â”† 10.652067 â”† 0.0  â”† 2.249194 â”† 3.263548 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    /home/jsr-p/projects/stats-packages/did-stepwise/.venv/lib/python3.12/site-packages/pyfixest/estimation/feols_.py:2628: UserWarning: 
                4 variables dropped due to multicollinearity.
                The following variables are dropped: ['C(t)[T.3]', 'C(t)[T.4]', 'C(t)[T.5]', 'C(t)[T.6]'].
                

    shape: (5, 7)
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ term â”† estimate â”† se       â”† tstat     â”† pval â”† lower    â”† upper    â”‚
    â”‚ ---  â”† ---      â”† ---      â”† ---       â”† ---  â”† ---      â”† ---      â”‚
    â”‚ str  â”† f64      â”† f64      â”† f64       â”† f64  â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ 0    â”† 0.505401 â”† 0.057061 â”† 8.857207  â”† 0.0  â”† 0.393562 â”† 0.617241 â”‚
    â”‚ 1    â”† 0.937251 â”† 0.094178 â”† 9.951911  â”† 0.0  â”† 0.752663 â”† 1.12184  â”‚
    â”‚ 2    â”† 1.446173 â”† 0.130892 â”† 11.048591 â”† 0.0  â”† 1.189625 â”† 1.702722 â”‚
    â”‚ 3    â”† 1.873075 â”† 0.187628 â”† 9.982922  â”† 0.0  â”† 1.505324 â”† 2.240826 â”‚
    â”‚ 4    â”† 2.773142 â”† 0.289131 â”† 9.591315  â”† 0.0  â”† 2.206446 â”† 3.339837 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    shape: (5, 7)
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ term â”† estimate â”† se       â”† tstat     â”† pval â”† lower    â”† upper    â”‚
    â”‚ ---  â”† ---      â”† ---      â”† ---       â”† ---  â”† ---      â”† ---      â”‚
    â”‚ str  â”† f64      â”† f64      â”† f64       â”† f64  â”† f64      â”† f64      â”‚
    â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡
    â”‚ 0    â”† 0.492878 â”† 0.054642 â”† 9.020127  â”† 0.0  â”† 0.385779 â”† 0.599976 â”‚
    â”‚ 1    â”† 0.934418 â”† 0.091581 â”† 10.203217 â”† 0.0  â”† 0.75492  â”† 1.113916 â”‚
    â”‚ 2    â”† 1.43822  â”† 0.129478 â”† 11.107868 â”† 0.0  â”† 1.184444 â”† 1.691996 â”‚
    â”‚ 3    â”† 1.886186 â”† 0.184845 â”† 10.20414  â”† 0.0  â”† 1.52389  â”† 2.248483 â”‚
    â”‚ 4    â”† 2.77223  â”† 0.276423 â”† 10.028957 â”† 0.0  â”† 2.230442 â”† 3.314018 â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

------------------------------------------------------------------------

## Some theory

In the following:

- $`Y_{i, t}`$ is outcome for unit $`i`$ in period $`t`$.

- $`E_{i}`$ treatment date for unit $`i`$

- $`K_{i, t} = t - E_{i}`$ relative treatment time for unit $`i`$ in
  period $`t`$

- $`D_{i, t} = \mathbf{1}\{K_{i, t} \geq 0\}`$ treatment indicator for
  unit $`i`$ in period $`t`$

### SGDD vs SWDD estimators

Harmon characterizes two groups of DID estimators:

- **Subgroup Difference-in-Differences** (SGDD)

- **Stepwise Difference-in-Differences** (SWDD)

SGDD estimators have the form:

``` math
\begin{aligned}
    \hat{\gamma}^{SGDD}_{i, h}
    = (Y_{i, E_{i} + h} - Y_{i, E_{i} - 1})
    - \frac{1}{\mathcal{N}}
    \sum_{j: D_{j, E_{i + h} = 0}}
    (Y_{j, E_{i} + h} - Y_{j, E_{i} - 1}).
\end{aligned}
```

where we in the right part sum over all those $`j`$ who are not treated
by $`E_{i
            + h}`$ (i.e.Â $`D_{j, E_{i + h} = 0}`$).

OOH, SWDD estimators have the form:

``` math
\begin{aligned}
    \hat{\gamma}^{SWDD}_{i, h}
    =
    \sum_{k = 0}^{h}
    \left[
        (Y_{i, E_{i} + k} - Y_{i, E_{i} + k - 1})
        -
        \frac{1}{\mathcal{N}}
        \sum_{j: D_{j, E_{i + k} = 0}}
        (Y_{j, E_{i} + k} - Y_{j, E_{i} + k - 1})
        \right]
\end{aligned}
```

where $`\mathcal{N}^{-1}`$ is a normalization factor for the inner sum
i.e.Â it differs for each $`k`$. Note that the first term telescopes such
that

``` math
\begin{aligned}
    \sum_{k = 0}^{h}
    (Y_{i, E_{i} + k} - Y_{i, E_{i} + k - 1})
     & =
    (Y_{i, E_{i}} - Y_{i, E_{i}- 1})
    +
    (Y_{i, E_{i} + 1} - Y_{i, E_{i}})
    +
    \cdots
    +
    (Y_{i, E_{i} + h} - Y_{i, E_{i} + h - 1}) \\
     & =
    (Y_{i, E_{i} + h} - Y_{i, E_{i} - 1})
\end{aligned}
```

and thus

``` math
\begin{aligned}
    \hat{\gamma}^{SWDD}_{i, h}
    =
    (Y_{i, E_{i} + h} - Y_{i, E_{i} - 1})
    -
    \sum_{k = 0}^{h}
    \left[
        \frac{1}{\mathcal{N}}
        \sum_{j: D_{j, E_{i + k} = 0}}
        (Y_{j, E_{i} + k} - Y_{j, E_{i} + k - 1})
        \right]
\end{aligned}
```

Comparing $`\hat{\gamma}^{SWDD}_{i, h}`$ to
$`\hat{\gamma}^{SGDD}_{i, h}`$ we see that the SWDD estimator
potentially includes more information than the SGDD estimator, while it
includes the stepwise differences for the non-treated units; the
stepwise comparisons use the time tuples $`\{(E_{i} + k, E_{i} + k -
    1)\}_{k=0}^{h}`$. Because of the extra comparisons in the control
group, the SWDD estimator potentially has a lower variance (is more
efficient) than the SGDD estimator for longer horizons; see the paper
(in particular the online appendix) for details.

------------------------------------------------------------------------

### Examples from paper

- [Numerical results](scripts/harmon_simexperiment.py)
  - [Output](output/harmon_simexperiment.txt)
- [Illustrative example of SWDD efficiency gains over
  SGDD](scripts/harmon_ex.py)
  - [Output](output/harmon_ex.txt)

### Imputation estimator

It turns out that the SWDD estimator of Harmon can be written as an
imputation estimator ala.
[BJS](https://academic.oup.com/restud/article/91/6/3253/7601390);
concretely, we estimate the $\hat{\gamma}^{SWDD}_{i, h}$â€™s using the BJS
imputation estimator on a transformed dataset. Hence, this package
depends on the `did_imp`
[package](https://github.com/jsr-p/did-imputation). See the
[paper](https://web.econ.ku.dk/nharmon/docs/harmon2022difference.pdf)
for more details.

## Development

``` bash
git clone git@github.com:jsr-p/did-stepwise.git
cd tabx
uv venv
uv sync --all-extras
```

### Testing

- ğŸš§ğŸ”¨â³Work in progress! ğŸš§ğŸ”¨â³
- Donâ€™t open the `tests` folder yet; ğŸ inside

### Docs

- ğŸš§ğŸ”¨â³Work in progress! ğŸš§ğŸ”¨â³

## References

- [Harmon
  paper](https://web.econ.ku.dk/nharmon/docs/harmon2022difference.pdf)

Code inspiration taken from:

- <https://github.com/nikoharm/did_stepwise>
